Salut ‚Äî guide d'intervention serveur Ollama Railway

R√©sum√©
Le serveur Ollama sur Railway retourne une erreur 500. Voici les √©tapes pour diagnostiquer et corriger le probl√®me.

üéØ Actions Imm√©diates

1. Acc√©der √† Railway Dashboard
   - Aller sur https://railway.app
   - Se connecter
   - Trouver le projet avec le service Ollama
   - URL actuelle: https://bot-production-b9d6.up.railway.app

2. Consulter les Logs (PRIORIT√â 1)
   - Ouvrir le service Ollama
   - Aller dans l'onglet "Logs"
   - Chercher les erreurs r√©centes:
     * Error 500
     * Out of memory (OOM)
     * Model not found
     * Failed to load model
     * Timeout

3. Red√©marrer le Serveur (Solution Rapide)
   - Dans Railway Dashboard
   - Service Ollama ‚Üí Settings ‚Üí Restart
   - Attendre 1-2 minutes
   - Tester √† nouveau

4. V√©rifier les Variables d'Environnement
   - Service Ollama ‚Üí Variables
   - V√©rifier: OLLAMA_MODEL=deepseek-coder:latest
   - Si manquant, l'ajouter

5. V√©rifier les Ressources
   - Service Ollama ‚Üí Settings ‚Üí Resources
   - RAM disponible: Le mod√®le deepseek-coder n√©cessite ~2-4GB
   - Plan gratuit Railway = 512MB (insuffisant!)

üîß Solutions Selon le Probl√®me

Probl√®me: M√©moire Insuffisante (OOM)
Solutions:
1. Augmenter les ressources Railway (plan payant)
2. Utiliser un mod√®le plus l√©ger (mistral:7b, llama2:7b)
3. Modifier VITE_OLLAMA_MODEL dans .env

Probl√®me: Mod√®le Non Charg√©
Solutions:
1. V√©rifier: ollama list (via Railway CLI ou terminal)
2. T√©l√©charger: ollama pull deepseek-coder:latest
3. V√©rifier variable OLLAMA_MODEL

Probl√®me: Timeout
Solutions:
1. R√©duire num_predict dans les options
2. Utiliser un mod√®le plus rapide

üöÄ Solution Alternative: DeepSeek API (Recommand√©)

Si Ollama continue √† poser probl√®me:

1. Obtenir une cl√© API DeepSeek
   - https://platform.deepseek.com
   - Cr√©er compte (gratuit)
   - G√©n√©rer cl√© API

2. Configurer dans le projet
   - Cr√©er/modifier .env √† la racine
   - Ajouter: VITE_DEEPSEEK_API_KEY=sk-votre_cle
   - Red√©marrer le serveur dev

3. Test
   - Le coach utilisera automatiquement DeepSeek API
   - Fonctionne imm√©diatement
   - Co√ªt: ~$0.14 pour 1M tokens

üìã Checklist

Diagnostic:
- [ ] Consulter logs Railway
- [ ] Identifier type d'erreur
- [ ] V√©rifier variables d'environnement
- [ ] V√©rifier ressources (RAM)

Actions:
- [ ] Red√©marrer serveur Ollama
- [ ] V√©rifier mod√®le charg√©
- [ ] Augmenter ressources si n√©cessaire
- [ ] Tester API apr√®s corrections

Alternative:
- [ ] Configurer DeepSeek API fallback
- [ ] Tester coach avec DeepSeek API

‚úÖ R√©sultat Attendu

Apr√®s intervention:
- ‚úÖ /api/generate retourne Status 200
- ‚úÖ /api/chat retourne Status 200
- ‚úÖ Coach r√©pond aux questions
- ‚úÖ R√©ponses en fran√ßais

üìÑ Fichiers cr√©√©s:
- GUIDE_INTERVENTION_SERVEUR_OLLAMA.md (guide d√©taill√©)
- INTERVENTION_SERVEUR_RAILWAY.md (guide Railway)
- COPIEZ_ICI_INTERVENTION_SERVEUR.txt (ce fichier)

