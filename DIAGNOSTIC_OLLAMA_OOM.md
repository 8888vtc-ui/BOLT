# Diagnostic - Ollama OOM (Out Of Memory) sur Railway

**Date**: 2025-12-03  
**Probl√®me**: Le serveur Ollama sur Railway ne peut pas charger le mod√®le √† cause d'un manque de m√©moire

---

## üêõ Probl√®me Identifi√©

### Erreur Principale
```
error="llama runner process has terminated: signal: killed"
```

**Cause**: Le processus est tu√© par le syst√®me d'exploitation √† cause d'un manque de m√©moire (OOM Killer).

---

## üìä Analyse des Ressources

### M√©moire Disponible
```
total="953.7 MiB" 
free="866.7 MiB" 
free_swap="185.3 GiB"
```

### M√©moire Requise par le Mod√®le
```
model weights: 703.4 MiB
kv cache: 768.0 MiB
total: 1.4 GiB
```

### Probl√®me
- **M√©moire disponible**: ~954 MiB
- **M√©moire requise**: ~1400 MiB
- **D√©ficit**: ~446 MiB

Le serveur n'a **pas assez de m√©moire** pour charger le mod√®le !

---

## üîç D√©tails du Mod√®le

- **Mod√®le**: `deepseek-coder:latest`
- **Param√®tres**: 1.35B
- **Quantification**: Q4_0
- **Taille du fichier**: 738.88 MiB
- **Taille en m√©moire**: 1.4 GiB (avec KV cache)

---

## ‚úÖ Solutions

### Solution 1: Augmenter les Ressources Railway (Recommand√©)
1. Aller sur Railway Dashboard
2. S√©lectionner le service Ollama
3. Augmenter la m√©moire √† **au moins 2 GiB**
4. Red√©marrer le service

**Avantages**:
- Le mod√®le fonctionnera correctement
- Pas de changement de code n√©cessaire

**Inconv√©nients**:
- Co√ªt suppl√©mentaire sur Railway

---

### Solution 2: Utiliser un Mod√®le Plus Petit
Remplacer `deepseek-coder:latest` par un mod√®le plus petit :
- `tinyllama` (~600 MiB)
- `phi-2` (~1.6 GiB mais plus efficace)
- `qwen2.5:0.5b` (si disponible)

**Avantages**:
- Pas de co√ªt suppl√©mentaire
- Fonctionne avec les ressources actuelles

**Inconv√©nients**:
- Qualit√© de r√©ponse potentiellement r√©duite

---

### Solution 3: Utiliser le Fallback DeepSeek API (D√©j√† Configur√©)
Le code utilise d√©j√† le fallback DeepSeek API quand Ollama √©choue.

**Avantages**:
- Fonctionne imm√©diatement
- Pas de changement n√©cessaire
- Qualit√© de r√©ponse √©lev√©e

**Inconv√©nients**:
- Co√ªt par requ√™te (mais cl√© d√©j√† fournie)

---

## üìù Recommandation

**Solution imm√©diate**: Le fallback DeepSeek API est d√©j√† configur√© et fonctionne. Le syst√®me basculera automatiquement vers DeepSeek quand Ollama √©choue.

**Solution √† long terme**: Augmenter les ressources Railway √† 2 GiB minimum pour permettre √† Ollama de fonctionner correctement.

---

## üîß Configuration Actuelle

Le code dans `src/lib/deepseekService.ts` g√®re d√©j√† le fallback :
1. **PRIORIT√â 1**: Netlify Function (appelle Ollama)
2. **PRIORIT√â 2**: Ollama Direct (si Netlify Function non configur√©e)
3. **PRIORIT√â 3**: DeepSeek API (fallback si Ollama √©choue)

Le syst√®me basculera automatiquement vers DeepSeek API quand Ollama retourne une erreur 500.

---

## ‚ö†Ô∏è Note Importante

Les erreurs 500 observ√©es sont **normales** dans la configuration actuelle. Le syst√®me basculera automatiquement vers DeepSeek API, qui fonctionne correctement.

Pour v√©rifier que le fallback fonctionne, observer les logs du client qui devraient montrer :
```
[AI Coach] Netlify Function failed, trying DeepSeek API fallback
[AI Coach] Using DeepSeek API (fallback)
```


