# Guide d'Intervention - Serveur Ollama (Erreur 500)

**Date**: 2025-01-02  
**Probl√®me**: Le serveur Ollama retourne une erreur 500 sur `/api/generate` et `/api/chat`

---

## üîç Diagnostic Initial

### √âtat Actuel
- ‚úÖ Serveur Ollama accessible (Status 200 sur `/api/tags`)
- ‚úÖ Mod√®le `deepseek-coder:latest` disponible
- ‚ùå `/api/generate` retourne erreur 500
- ‚ùå `/api/chat` retourne erreur 500

### URL du Serveur
- **URL**: `https://bot-production-b9d6.up.railway.app`
- **Plateforme**: Railway
- **Mod√®le**: `deepseek-coder:latest`

---

## üìã √âtapes d'Intervention

### √âtape 1: V√©rifier les Logs Railway

1. **Acc√©der √† Railway Dashboard**
   - Aller sur https://railway.app
   - Se connecter avec votre compte
   - Trouver le projet contenant le serveur Ollama

2. **Consulter les Logs**
   - Ouvrir le service Ollama
   - Cliquer sur "Logs" ou "View Logs"
   - Chercher les erreurs r√©centes (erreur 500)
   - Noter les messages d'erreur d√©taill√©s

3. **V√©rifier les Erreurs Communes**
   - Erreurs de m√©moire (OOM - Out of Memory)
   - Erreurs de mod√®le non charg√©
   - Erreurs de configuration
   - Erreurs de timeout

---

### √âtape 2: V√©rifier la Configuration du Mod√®le

#### Option A: Via Railway CLI

```bash
# Installer Railway CLI si n√©cessaire
npm i -g @railway/cli

# Se connecter
railway login

# V√©rifier les variables d'environnement
railway variables

# V√©rifier les logs en temps r√©el
railway logs
```

#### Option B: Via Railway Dashboard

1. Ouvrir le service Ollama
2. Aller dans "Variables"
3. V√©rifier:
   - `OLLAMA_MODEL` (devrait √™tre `deepseek-coder:latest`)
   - `OLLAMA_HOST` (si configur√©)
   - `OLLAMA_PORT` (si configur√©)
   - Variables de m√©moire/ressources

---

### √âtape 3: Red√©marrer le Serveur

#### Via Railway Dashboard

1. Ouvrir le service Ollama
2. Cliquer sur "Restart" ou "Redeploy"
3. Attendre le red√©marrage (1-2 minutes)
4. Tester √† nouveau l'API

#### Via Railway CLI

```bash
railway restart
```

---

### √âtape 4: V√©rifier les Ressources

#### Probl√®mes Courants

1. **M√©moire Insuffisante**
   - Le mod√®le `deepseek-coder` n√©cessite ~2-4GB de RAM
   - V√©rifier la configuration Railway (plan gratuit = 512MB, peut √™tre insuffisant)

2. **Timeout**
   - Les requ√™tes peuvent prendre plus de 30 secondes
   - V√©rifier les timeouts Railway

3. **Mod√®le Non Charg√©**
   - Le mod√®le peut ne pas √™tre charg√© au d√©marrage
   - V√©rifier les logs de d√©marrage

---

### √âtape 5: Tester l'API Directement

#### Test avec curl

```bash
# Test /api/tags
curl https://bot-production-b9d6.up.railway.app/api/tags

# Test /api/generate (format simple)
curl -X POST https://bot-production-b9d6.up.railway.app/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-coder:latest",
    "prompt": "Hello",
    "stream": false
  }'

# Test /api/chat
curl -X POST https://bot-production-b9d6.up.railway.app/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-coder:latest",
    "messages": [
      {"role": "user", "content": "Hello"}
    ],
    "stream": false
  }'
```

#### Test avec PowerShell

```powershell
# Test /api/generate
$body = @{
    model = "deepseek-coder:latest"
    prompt = "Hello"
    stream = $false
} | ConvertTo-Json

Invoke-WebRequest -Uri "https://bot-production-b9d6.up.railway.app/api/generate" `
  -Method POST -Body $body -ContentType "application/json"
```

---

### √âtape 6: Solutions Possibles

#### Solution 1: Red√©marrer le Serveur
- **Action**: Red√©marrer le service Ollama sur Railway
- **Impact**: Peut r√©soudre les probl√®mes de m√©moire ou de mod√®le non charg√©

#### Solution 2: Augmenter les Ressources
- **Action**: Passer √† un plan Railway avec plus de RAM
- **Impact**: R√©sout les probl√®mes de m√©moire insuffisante
- **Co√ªt**: Plan payant Railway

#### Solution 3: Changer de Mod√®le
- **Action**: Utiliser un mod√®le plus l√©ger (llama2, mistral, etc.)
- **Impact**: R√©duit l'utilisation m√©moire
- **Code**: Modifier `VITE_OLLAMA_MODEL` dans `.env`

#### Solution 4: V√©rifier la Configuration Ollama
- **Action**: V√©rifier que Ollama est correctement configur√© sur Railway
- **Impact**: Peut r√©v√©ler des probl√®mes de configuration

#### Solution 5: Utiliser le Fallback DeepSeek API
- **Action**: Configurer `VITE_DEEPSEEK_API_KEY` dans `.env`
- **Impact**: Le coach utilisera DeepSeek API au lieu d'Ollama
- **Co√ªt**: Payant (mais tr√®s √©conomique)

---

## üîß Configuration Alternative: DeepSeek API (Fallback)

Si le serveur Ollama ne peut pas √™tre corrig√© rapidement, vous pouvez utiliser le fallback DeepSeek API :

### √âtapes

1. **Obtenir une Cl√© API DeepSeek**
   - Aller sur https://platform.deepseek.com
   - Cr√©er un compte
   - G√©n√©rer une cl√© API

2. **Configurer dans le Projet**
   - Cr√©er/modifier `.env` √† la racine du projet
   - Ajouter: `VITE_DEEPSEEK_API_KEY=votre_cle_api`
   - Red√©marrer le serveur de d√©veloppement

3. **Test**
   - Le coach utilisera automatiquement DeepSeek API si Ollama √©choue
   - Les messages seront en fran√ßais automatiquement

---

## üìä Checklist d'Intervention

- [ ] Consulter les logs Railway
- [ ] V√©rifier les variables d'environnement
- [ ] V√©rifier les ressources (RAM, CPU)
- [ ] Red√©marrer le serveur Ollama
- [ ] Tester `/api/generate` apr√®s red√©marrage
- [ ] Tester `/api/chat` apr√®s red√©marrage
- [ ] Si √©chec ‚Üí Configurer DeepSeek API fallback
- [ ] Documenter la solution trouv√©e

---

## üÜò En Cas d'√âchec

Si aucune solution ne fonctionne :

1. **Utiliser DeepSeek API** (recommand√©)
   - Configuration rapide
   - Fonctionne imm√©diatement
   - Co√ªt tr√®s faible (~$0.14 pour 1M tokens)

2. **D√©ployer un Nouveau Serveur Ollama**
   - Cr√©er un nouveau service Railway
   - Installer Ollama
   - T√©l√©charger le mod√®le
   - Mettre √† jour `VITE_OLLAMA_URL`

3. **Utiliser un Service Ollama Externe**
   - Services comme Hugging Face Spaces
   - Services Ollama h√©berg√©s

---

## üìù Notes

- Le probl√®me semble √™tre c√¥t√© serveur Railway, pas c√¥t√© code
- Le code a √©t√© am√©lior√© pour g√©rer les erreurs et essayer plusieurs formats
- Le fallback DeepSeek API est pr√™t √† √™tre utilis√© si n√©cessaire

---

## ‚úÖ R√©sultat Attendu

Apr√®s intervention, le coach devrait :
- ‚úÖ R√©pondre aux questions des utilisateurs
- ‚úÖ Analyser les positions de jeu
- ‚úÖ Fournir des conseils strat√©giques
- ‚úÖ Fonctionner en fran√ßais automatiquement


